{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premade Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:32.436876Z",
     "start_time": "2020-03-27T23:24:30.324693Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:22:32.824601Z",
     "start_time": "2020-03-27T22:22:32.820191Z"
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:35.022206Z",
     "start_time": "2020-03-27T23:24:35.010163Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df = pd.read_csv(\"../data/winequality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:22:38.813362Z",
     "start_time": "2020-03-27T22:22:38.703791Z"
    }
   },
   "outputs": [],
   "source": [
    "display(wines_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:46.779511Z",
     "start_time": "2020-03-27T23:24:46.772058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# tf doesn't like spaces in col names so I replace them with _ \n",
    "new_col_list = []\n",
    "for col_name in wines_df.columns:\n",
    "    new_col_names = col_name.replace(\" \", \"_\")\n",
    "    new_col_list.append(new_col_names)\n",
    "print(new_col_list)\n",
    "wines_df.columns = new_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:37:20.895272Z",
     "start_time": "2020-03-27T23:37:20.889323Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining a few helpful constants for parsing the dataset\n",
    "\n",
    "CSV_COLUMN_NAMES = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "\n",
    "\n",
    "QUALITIES = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "OBSERVED_QUALITIES = [3,4,5,6,7,8]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible solution for qualities:\n",
    "\n",
    "1. set observed_qualities = [3,4,5,6,7,8]\n",
    "\n",
    "2. set count_classes to len(observed_qualities) + 1  = 6 + 1 = 7\n",
    "\n",
    "\n",
    "\n",
    "doulepse otan ebala gia count classes = 9 dhladh timh megaluterh tou max observed quality 8?\n",
    "\n",
    "h logikh m leei oti tha eprepe na douleuei gia count classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:30:35.990052Z",
     "start_time": "2020-03-27T23:30:35.982612Z"
    }
   },
   "outputs": [],
   "source": [
    "count_classes = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to supply a training, a validation and a test set to TF, so we have to split the dataset to three separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:27:27.277804Z",
     "start_time": "2020-03-27T23:27:27.239933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>31.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>10.3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.213</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.057</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99498</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.89</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.074</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.055</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "1560            7.8              0.60         0.26             2.0      0.080   \n",
       "307            10.3              0.41         0.42             2.4      0.213   \n",
       "1070            9.3              0.33         0.45             1.5      0.057   \n",
       "59              7.3              0.39         0.31             2.4      0.074   \n",
       "491             9.2              0.41         0.50             2.5      0.055   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "1560                 31.0                 131.0  0.99622  3.21       0.52   \n",
       "307                   6.0                  14.0  0.99940  3.19       0.62   \n",
       "1070                 19.0                  37.0  0.99498  3.18       0.89   \n",
       "59                    9.0                  46.0  0.99620  3.41       0.54   \n",
       "491                  12.0                  25.0  0.99520  3.34       0.79   \n",
       "\n",
       "      alcohol  \n",
       "1560      9.9  \n",
       "307       9.5  \n",
       "1070     11.1  \n",
       "59        9.4  \n",
       "491      13.3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wines_df = wines_df.sample(frac=1) # shuffle the data of the wines_df\n",
    "\n",
    "# almost 70% training , 15% validation, 15% test set\n",
    "train_valid_df, test_set = train_test_split(wines_df, test_size=0.15) \n",
    "train_set, valid_set = train_test_split(train_valid_df, test_size=0.15)\n",
    "\n",
    "\n",
    "train_y = train_set.pop('quality')\n",
    "test_y = test_set.pop('quality')\n",
    "\n",
    "# The target label column has now been removed from the features.\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "\n",
    "data_srs = wines_df.iloc[0,0:-1]\n",
    "\n",
    "my_json = data_srs.to_json()\n",
    "\n",
    "my_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T14:29:40.053275Z",
     "start_time": "2020-02-20T14:29:40.046534Z"
    }
   },
   "source": [
    "## Create a dataset input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "* features - A Python dictionary in which:\n",
    "    * Each key is the name of a feature.\n",
    "    * Each value is an array containing all of the feature's values.\n",
    "* label - A tensor containing the values of the target label for every example.\n",
    "\n",
    "Just to demonstrate the format of the input function, here's a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:27:38.308294Z",
     "start_time": "2020-03-27T23:27:38.298337Z"
    }
   },
   "outputs": [],
   "source": [
    "def a_basic_input_function():\n",
    "    features = {'fixed_acidity': np.array([6.9, 6.2, 7.1]),\n",
    "                'volatile_acidity': np.array([0.685, 0.58 , 0.43 ]),\n",
    "                'citric_acid': np.array([0.  , 0.  , 0.42]),\n",
    "                'residual_sugar': np.array([2.5, 1.6, 5.5]),\n",
    "                'chlorides': np.array([0.105, 0.065, 0.07]),\n",
    "                'free_sulfur_dioxide': np.array([22.,  8., 29.]),\n",
    "                'total_sulfur_dioxide': np.array([37.,  18., 129.]),\n",
    "                'density': np.array([0.9966, 0.9966, 0.9973]),\n",
    "                'pH': np.array([3.46, 3.56, 3.42]),\n",
    "                'sulphates': np.array([0.57, 0.84, 0.72]),\n",
    "                'alcohol':np.array([10.6,  9.4, 10.5])}\n",
    "    labels = np.array([6, 5, 6])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your input function may generate the features dictionary and label list any way you like. However, we recommend using TensorFlow's Dataset API, which can parse all sorts of data.\n",
    "\n",
    "The Dataset API can handle a lot of common cases for you. For example, using the Dataset API, you can easily read in records from a large collection of files in parallel and join them into a single stream.\n",
    "\n",
    "To keep things simple in this example you are going to load the data with pandas, and build an input pipeline from this in-memory data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**features (dict)** keys: CSV_COLUMN_NAMES [0:-1] (namely excluding the label of the target variable) , values: np.arrays of the features values \n",
    "\n",
    "**labels (np.array)** the values of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:27:41.032263Z",
     "start_time": "2020-03-27T23:27:41.027476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed_acidity',\n",
       " 'volatile_acidity',\n",
       " 'citric_acid',\n",
       " 'residual_sugar',\n",
       " 'chlorides',\n",
       " 'free_sulfur_dioxide',\n",
       " 'total_sulfur_dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:30:53.501129Z",
     "start_time": "2020-03-27T23:30:53.495095Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def input_fn(features = CSV_COLUMN_NAMES[0:-1] , labels = OBSERVED_QUALITIES, training=True, batch_size=55):\n",
    "    \"\"\" \n",
    "    \n",
    "    An input function for the training and evaluation procedures \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the inputs to a Dataset. \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "        \n",
    "                                                 \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:27:49.072139Z",
     "start_time": "2020-03-27T23:27:49.067957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_set.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:31:07.559912Z",
     "start_time": "2020-03-27T23:31:07.548426Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp69sagwdz\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp69sagwdz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f48808b7d10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 6 classes. [3-8]\n",
    "    n_classes=count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:31:17.779297Z",
     "start_time": "2020-03-27T23:31:15.358657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp69sagwdz/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3465486, step = 0\n",
      "INFO:tensorflow:global_step/sec: 259.932\n",
      "INFO:tensorflow:loss = 1.9587638, step = 100 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.867\n",
      "INFO:tensorflow:loss = 1.9142903, step = 200 (0.248 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 231 into /tmp/tmp69sagwdz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8755589.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f4877da3c10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "\n",
    "# steps = number_of_batches per epoch = 231 batches per epoch \n",
    "\n",
    "# batch_size = 55 \n",
    "\n",
    "# number_of_training_samples = 1155 * 11 = 12705\n",
    "\n",
    "# number_of_batches = 12705/55 = 231 in the training set\n",
    "\n",
    "# 1 epoch equals to a parsing of the whole train_set\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train_set, train_y, training=True),\n",
    "    steps=231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T09:08:03.347416Z",
     "start_time": "2020-03-20T09:08:02.320280Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the call to the train method, *you did not pass the steps argument to evaluate*. The input_fn for eval only yields a **single epoch** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval_result dictionary also contains *the average_loss* (mean loss per sample), *the loss* (mean loss per mini-batch) and the value of the *estimator's global_step* (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:35.654342Z",
     "start_time": "2020-02-21T11:34:35.649588Z"
    }
   },
   "outputs": [],
   "source": [
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions (inferring) from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:50.280429Z",
     "start_time": "2020-02-21T11:49:50.260207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "predict_x = {\n",
    "    'fixed_acidity': [7.1, 5.6, 0.7],\n",
    "    'volatile_acidity': [0.150, 0.760, 0,352],\n",
    "    'citric_acid': [0.0, 0.25, 0.13],\n",
    "    'residual_sugar': [0.3, 1.5, 2.4],\n",
    "    'chlorides': [0.034, 0.012, 0.056],\n",
    "    'free_sulfur_dioxide': [14.0, 12.0, 15.0],\n",
    "    'total_sulfur_dioxide':[45.0, 12.0, 56.0],\n",
    "    'density':[0.98334, 0.96423, 0.9731],\n",
    "    'pH':[3.12, 3.56, 3.78],\n",
    "    'sulphates':[0.56, 0.75, 0.67],\n",
    "    'alcohol':[12.5, 11.2, 10.3]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:52:11.594298Z",
     "start_time": "2020-02-21T11:52:11.589995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predictions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict method returns a Python iterable, yielding a dictionary of prediction results for each example. The following code prints a few predictions and their probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:55.426134Z",
     "start_time": "2020-02-21T11:49:54.923986Z"
    }
   },
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Estimator \n",
    "\n",
    "1. input_func : transforms raw data to Dataset objects.\n",
    "\n",
    "2. feature_func : function that defines the feature cols of the datasets\n",
    "\n",
    "3. model_func : heart of the estimator. This func specifies the type of model used to make predictions and its characteristics e.g DNN with k layers so on and so forth\n",
    "\n",
    "4. train_func, eval_func, test_func : functions relevant to implement the training, evaluation and testing procedures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance (why we need an input func in our workflow?)\n",
    "\n",
    "\n",
    "Functionality (what does an input func do?)\n",
    "\n",
    "\n",
    "Implementation (how does the input func do what it is supposed to do?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func(csv) ----> [train_set, valid_set, test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_func():\n",
    "    ...  # manipulate dataset, extracting the feature dict and the label\n",
    "    return feature_dict, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_func(csv_header) ------> (features, target)\n",
    "\n",
    "\n",
    "\n",
    "* We need to define the data type for every attribute column.\n",
    "\n",
    "* We need to normalize each attribute according to its type and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns including their names and type of data they contain.\n",
    "\n",
    "def feature_func(csv_header):\n",
    "\n",
    "    population = tf.feature_column.numeric_column('population')\n",
    "    crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "    median_education = tf.feature_column.numeric_column(\n",
    "        'median_education', normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_func or Model_class? probably the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ) -----> wine.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate an estimator, by passing in the feature columns.\n",
    "\n",
    "\n",
    "def model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ):\n",
    "    # using premade at first then extend it to custom\n",
    "    wine_classifier = \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class BPSomeClass(object):\n",
    "    \"\"\"Brief class description\n",
    "    \n",
    "    Some more extensive description\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    attr1 : string\n",
    "        Purpose of attr1.\n",
    "    attr2 : float\n",
    "        Purpose of attr2.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, param1, param2, param3=0):\n",
    "        \"\"\"Example of docstring on the __init__ method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param1 : str\n",
    "            Description of `param1`.\n",
    "        param2 : float\n",
    "            Description of `param2`.\n",
    "        param3 : int, optional\n",
    "            Description of `param3`, defaults to 0.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.attr1 = param1\n",
    "        self.attr2 = param2\n",
    "        print(param3 // 4)\n",
    "    \n",
    "    @property\n",
    "    def attribute2(self):\n",
    "        return self.attr2\n",
    "    \n",
    "    @attribute2.setter\n",
    "    def attribute2(self, new_attr2):\n",
    "        if not isinstance(float, new_attr2):\n",
    "            raise ValueError(\"attribute2 must be a float, not {0}\".format(new_attr2))\n",
    "        self.attr2 = new_attr2\n",
    "\n",
    "\n",
    "bp_obj = BPSomeClass(\"a\", 1.618)\n",
    "print(bp_obj.attribute2)\n",
    "bp_obj.attribute2 = 3.236\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine.Classifier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# `input_fn` is the function created in Step 1\n",
    "\n",
    "def train_func(arg):\n",
    "    estimator.train(input_func=train_set, steps=2000)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## val_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_func(arg):\n",
    "    estimator.eval(input_func=eval_set, .....)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_func(arg):\n",
    "    estimator.test(input_func=test_set, .....)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Synthetica)",
   "language": "python",
   "name": "synthetica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
