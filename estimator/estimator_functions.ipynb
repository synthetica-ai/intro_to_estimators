{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premade Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:32.436876Z",
     "start_time": "2020-03-27T23:24:30.324693Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:22:32.824601Z",
     "start_time": "2020-03-27T22:22:32.820191Z"
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:35.022206Z",
     "start_time": "2020-03-27T23:24:35.010163Z"
    }
   },
   "outputs": [],
   "source": [
    "wines_df = pd.read_csv(\"../data/winequality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T22:22:38.813362Z",
     "start_time": "2020-03-27T22:22:38.703791Z"
    }
   },
   "outputs": [],
   "source": [
    "display(wines_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:24:46.779511Z",
     "start_time": "2020-03-27T23:24:46.772058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "# tf doesn't like spaces in col names so I replace them with _ \n",
    "new_col_list = []\n",
    "for col_name in wines_df.columns:\n",
    "    new_col_names = col_name.replace(\" \", \"_\")\n",
    "    new_col_list.append(new_col_names)\n",
    "print(new_col_list)\n",
    "wines_df.columns = new_col_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:22:53.136636Z",
     "start_time": "2020-03-28T00:22:53.127845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# defining a few helpful constants for parsing the dataset\n",
    "\n",
    "CSV_COLUMN_NAMES = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "\n",
    "\n",
    "QUALITIES = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "OBSERVED_QUALITIES = ['3', '4', '5', '6', '7', '8']\n",
    "\n",
    "print(type(OBSERVED_QUALITIES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible solution for qualities:\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/45813746/tensorflow-invalid-argument-assertation-failed-label-ids-must-n-classes\n",
    "\n",
    "1. observed_qualities = [3,4,5,6,7,8] \n",
    "\n",
    "2. amount of qualities = 6 = n_classes\n",
    "\n",
    "\n",
    "doulepse otan ebala gia count classes = 9 dhladh timh megaluterh tou max observed quality 8?\n",
    "\n",
    "h logikh m leei oti tha eprepe na douleuei gia count classes = 6\n",
    "\n",
    "\n",
    "tf docs\n",
    "\n",
    "\n",
    "* n_classes: Number of label classes. Defaults to 2, namely binary classification. Must be > 1.\n",
    "\n",
    "    I have multiclass classification with 6 classes so num_classes should be 6 am I right?\n",
    "    \n",
    "* label_vocabulary: A list of strings represents possible label values. If given, labels must be string type and have any value in label_vocabulary. If it is not given, that means labels are already encoded as integer or float within [0, 1] for n_classes=2 and encoded as integer values in {0, 1,..., n_classes-1} for n_classes>2 . Also there will be errors if vocabulary is not provided and labels are string.\n",
    "\n",
    "\n",
    "\n",
    "final solution\n",
    "\n",
    "1. either use n_classes = 6 and label_vocabulary = observed_qualities as **list of strings**.\n",
    "\n",
    "or\n",
    "\n",
    "2. use n_classes = 9 which is encoded as integer values in {0,1,....,n_classes-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to supply a training, a validation and a test set to TF, so we have to split the dataset to three separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:23:22.025023Z",
     "start_time": "2020-03-28T00:23:21.997475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.069</td>\n",
       "      <td>18.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.78</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.084</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.059</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.070</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99438</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.072</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "84              6.3              0.30         0.48             1.8      0.069   \n",
       "452             6.8              0.56         0.03             1.7      0.084   \n",
       "685             8.1              0.78         0.23             2.6      0.059   \n",
       "1045            6.9              0.44         0.00             1.4      0.070   \n",
       "167             7.3              0.55         0.03             1.6      0.072   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "84                   18.0                  61.0  0.99590  3.44       0.78   \n",
       "452                  18.0                  35.0  0.99680  3.44       0.63   \n",
       "685                   5.0                  15.0  0.99700  3.37       0.56   \n",
       "1045                 32.0                  38.0  0.99438  3.32       0.58   \n",
       "167                  17.0                  42.0  0.99560  3.37       0.48   \n",
       "\n",
       "      alcohol  \n",
       "84       10.3  \n",
       "452      10.0  \n",
       "685      11.3  \n",
       "1045     11.4  \n",
       "167       9.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wines_df = wines_df.sample(frac=1) # shuffle the data of the wines_df\n",
    "\n",
    "# almost 70% training , 15% validation, 15% test set\n",
    "train_valid_df, test_set = train_test_split(wines_df, test_size=0.15) \n",
    "train_set, valid_set = train_test_split(train_valid_df, test_size=0.15)\n",
    "\n",
    "\n",
    "train_y = train_set.pop('quality')\n",
    "test_y = test_set.pop('quality')\n",
    "\n",
    "# The target label column has now been removed from the features.\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:19:41.141442Z",
     "start_time": "2020-03-28T00:19:41.123438Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_string = train_y.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:19:41.856215Z",
     "start_time": "2020-03-28T00:19:41.848768Z"
    }
   },
   "outputs": [],
   "source": [
    "test_y_string = test_y.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "\n",
    "data_srs = wines_df.iloc[0,0:-1]\n",
    "\n",
    "my_json = data_srs.to_json()\n",
    "\n",
    "my_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T14:29:40.053275Z",
     "start_time": "2020-02-20T14:29:40.046534Z"
    }
   },
   "source": [
    "## Create a dataset input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "* features - A Python dictionary in which:\n",
    "    * Each key is the name of a feature.\n",
    "    * Each value is an array containing all of the feature's values.\n",
    "* label - A tensor containing the values of the target label for every example.\n",
    "\n",
    "Just to demonstrate the format of the input function, here's a simple implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:23:27.102557Z",
     "start_time": "2020-03-28T00:23:27.088739Z"
    }
   },
   "outputs": [],
   "source": [
    "def a_basic_input_function():\n",
    "    features = {'fixed_acidity': np.array([6.9, 6.2, 7.1]),\n",
    "                'volatile_acidity': np.array([0.685, 0.58 , 0.43 ]),\n",
    "                'citric_acid': np.array([0.  , 0.  , 0.42]),\n",
    "                'residual_sugar': np.array([2.5, 1.6, 5.5]),\n",
    "                'chlorides': np.array([0.105, 0.065, 0.07]),\n",
    "                'free_sulfur_dioxide': np.array([22.,  8., 29.]),\n",
    "                'total_sulfur_dioxide': np.array([37.,  18., 129.]),\n",
    "                'density': np.array([0.9966, 0.9966, 0.9973]),\n",
    "                'pH': np.array([3.46, 3.56, 3.42]),\n",
    "                'sulphates': np.array([0.57, 0.84, 0.72]),\n",
    "                'alcohol':np.array([10.6,  9.4, 10.5])}\n",
    "    labels = np.array([6, 5, 6])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your input function may generate the features dictionary and label list any way you like. However, we recommend using TensorFlow's Dataset API, which can parse all sorts of data.\n",
    "\n",
    "The Dataset API can handle a lot of common cases for you. For example, using the Dataset API, you can easily read in records from a large collection of files in parallel and join them into a single stream.\n",
    "\n",
    "To keep things simple in this example you are going to load the data with pandas, and build an input pipeline from this in-memory data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**features (dict)** keys: CSV_COLUMN_NAMES [0:-1] (namely excluding the label of the target variable) , values: np.arrays of the features values \n",
    "\n",
    "**labels (np.array)** the values of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T23:27:41.032263Z",
     "start_time": "2020-03-27T23:27:41.027476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed_acidity',\n",
       " 'volatile_acidity',\n",
       " 'citric_acid',\n",
       " 'residual_sugar',\n",
       " 'chlorides',\n",
       " 'free_sulfur_dioxide',\n",
       " 'total_sulfur_dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_COLUMN_NAMES[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:23:31.024927Z",
     "start_time": "2020-03-28T00:23:31.017925Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def input_fn(features = CSV_COLUMN_NAMES[0:-1] , labels = OBSERVED_QUALITIES, training=True, batch_size=55):\n",
    "    \"\"\" \n",
    "    \n",
    "    An input function for the training and evaluation procedures \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert the inputs to a Dataset. \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "        \n",
    "                                                 \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:23:38.716992Z",
     "start_time": "2020-03-28T00:23:38.711814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_set.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:23:41.866599Z",
     "start_time": "2020-03-28T00:23:41.855009Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpj66wjuee\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpj66wjuee', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f480dbd4990>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 6 classes. [3-8]\n",
    "    n_classes=6,\n",
    "    label_vocabulary=OBSERVED_QUALITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T00:24:22.644883Z",
     "start_time": "2020-03-28T00:24:22.530324Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value Tensor(\"normalize_element/component_11:0\", shape=(), dtype=string, device=/device:CPU:0) has insufficient rank for batching.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-adb44cdf8fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m classifier.train(\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     steps=231)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1185\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m   1186\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m-> 1187\u001b[0;31m               input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m-> 1024\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_context'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-adb44cdf8fc1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m classifier.train(\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     steps=231)\n",
      "\u001b[0;32m<ipython-input-66-8a932a134087>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(features, labels, training, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Convert the inputs to a Dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Shuffle and repeat if you are in training mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    433\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2354\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m     self._structure = nest.map_structure(\n\u001b[1;32m   2358\u001b[0m         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mto_batched_tensor_list\u001b[0;34m(element_spec, element)\u001b[0m\n\u001b[1;32m    346\u001b[0m   return _to_tensor_list_helper(\n\u001b[1;32m    347\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0;32m--> 348\u001b[0;31m           component), element_spec, element)\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[0;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m   return functools.reduce(\n\u001b[0;32m--> 322\u001b[0;31m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m   return functools.reduce(\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state, spec, component)\u001b[0m\n\u001b[1;32m    346\u001b[0m   return _to_tensor_list_helper(\n\u001b[1;32m    347\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0;32m--> 348\u001b[0;31m           component), element_spec, element)\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Synthetica/lib/python3.7/site-packages/tensorflow_core/python/framework/type_spec.py\u001b[0m in \u001b[0;36m_to_batched_tensor_list\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0mtensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value %s has insufficient rank for batching.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Value Tensor(\"normalize_element/component_11:0\", shape=(), dtype=string, device=/device:CPU:0) has insufficient rank for batching."
     ]
    }
   ],
   "source": [
    "# Train the Model.\n",
    "\n",
    "# steps = number_of_batches per epoch = 231 batches per epoch \n",
    "\n",
    "# batch_size = 55 \n",
    "\n",
    "# number_of_training_samples = 1155 * 11 = 12705\n",
    "\n",
    "# number_of_batches = 12705/55 = 231 in the training set\n",
    "\n",
    "# 1 epoch equals to a parsing of the whole train_set\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train_set, train_y_string, training=True),\n",
    "    steps=231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T09:08:03.347416Z",
     "start_time": "2020-03-20T09:08:02.320280Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the call to the train method, *you did not pass the steps argument to evaluate*. The input_fn for eval only yields a **single epoch** of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval_result dictionary also contains *the average_loss* (mean loss per sample), *the loss* (mean loss per mini-batch) and the value of the *estimator's global_step* (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:34:35.654342Z",
     "start_time": "2020-02-21T11:34:35.649588Z"
    }
   },
   "outputs": [],
   "source": [
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions (inferring) from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:50.280429Z",
     "start_time": "2020-02-21T11:49:50.260207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "predict_x = {\n",
    "    'fixed_acidity': [7.1, 5.6, 0.7],\n",
    "    'volatile_acidity': [0.150, 0.760, 0,352],\n",
    "    'citric_acid': [0.0, 0.25, 0.13],\n",
    "    'residual_sugar': [0.3, 1.5, 2.4],\n",
    "    'chlorides': [0.034, 0.012, 0.056],\n",
    "    'free_sulfur_dioxide': [14.0, 12.0, 15.0],\n",
    "    'total_sulfur_dioxide':[45.0, 12.0, 56.0],\n",
    "    'density':[0.98334, 0.96423, 0.9731],\n",
    "    'pH':[3.12, 3.56, 3.78],\n",
    "    'sulphates':[0.56, 0.75, 0.67],\n",
    "    'alcohol':[12.5, 11.2, 10.3]\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:52:11.594298Z",
     "start_time": "2020-02-21T11:52:11.589995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predictions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict method returns a Python iterable, yielding a dictionary of prediction results for each example. The following code prints a few predictions and their probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T11:49:55.426134Z",
     "start_time": "2020-02-21T11:49:54.923986Z"
    }
   },
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Estimator \n",
    "\n",
    "1. input_func : transforms raw data to Dataset objects.\n",
    "\n",
    "2. feature_func : function that defines the feature cols of the datasets\n",
    "\n",
    "3. model_func : heart of the estimator. This func specifies the type of model used to make predictions and its characteristics e.g DNN with k layers so on and so forth\n",
    "\n",
    "4. train_func, eval_func, test_func : functions relevant to implement the training, evaluation and testing procedures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance (why we need an input func in our workflow?)\n",
    "\n",
    "\n",
    "Functionality (what does an input func do?)\n",
    "\n",
    "\n",
    "Implementation (how does the input func do what it is supposed to do?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func(csv) ----> [train_set, valid_set, test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_func():\n",
    "    ...  # manipulate dataset, extracting the feature dict and the label\n",
    "    return feature_dict, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_func(csv_header) ------> (features, target)\n",
    "\n",
    "\n",
    "\n",
    "* We need to define the data type for every attribute column.\n",
    "\n",
    "* We need to normalize each attribute according to its type and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns including their names and type of data they contain.\n",
    "\n",
    "def feature_func(csv_header):\n",
    "\n",
    "    population = tf.feature_column.numeric_column('population')\n",
    "    crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "    median_education = tf.feature_column.numeric_column(\n",
    "        'median_education', normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_func or Model_class? probably the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ) -----> wine.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate an estimator, by passing in the feature columns.\n",
    "\n",
    "\n",
    "def model_func(feature_columns, hidden_units = [ some_layer_1_nodes , ... , some_layer_n_nodes], n_classes = 8 ):\n",
    "    # using premade at first then extend it to custom\n",
    "    wine_classifier = \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class BPSomeClass(object):\n",
    "    \"\"\"Brief class description\n",
    "    \n",
    "    Some more extensive description\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    attr1 : string\n",
    "        Purpose of attr1.\n",
    "    attr2 : float\n",
    "        Purpose of attr2.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, param1, param2, param3=0):\n",
    "        \"\"\"Example of docstring on the __init__ method.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param1 : str\n",
    "            Description of `param1`.\n",
    "        param2 : float\n",
    "            Description of `param2`.\n",
    "        param3 : int, optional\n",
    "            Description of `param3`, defaults to 0.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.attr1 = param1\n",
    "        self.attr2 = param2\n",
    "        print(param3 // 4)\n",
    "    \n",
    "    @property\n",
    "    def attribute2(self):\n",
    "        return self.attr2\n",
    "    \n",
    "    @attribute2.setter\n",
    "    def attribute2(self, new_attr2):\n",
    "        if not isinstance(float, new_attr2):\n",
    "            raise ValueError(\"attribute2 must be a float, not {0}\".format(new_attr2))\n",
    "        self.attr2 = new_attr2\n",
    "\n",
    "\n",
    "bp_obj = BPSomeClass(\"a\", 1.618)\n",
    "print(bp_obj.attribute2)\n",
    "bp_obj.attribute2 = 3.236\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine.Classifier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# `input_fn` is the function created in Step 1\n",
    "\n",
    "def train_func(arg):\n",
    "    estimator.train(input_func=train_set, steps=2000)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## val_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_func(arg):\n",
    "    estimator.eval(input_func=eval_set, .....)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_func(arg):\n",
    "    estimator.test(input_func=test_set, .....)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Synthetica)",
   "language": "python",
   "name": "synthetica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
